"use strict";(globalThis.webpackChunkt_1_c_docs=globalThis.webpackChunkt_1_c_docs||[]).push([[436],{6435:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"spikeyolo-v8-tracker/introduction","title":"SpikeYoloV8-Tracker Introduction","description":"SpikeYoloV8-Tracker is a complete end-to-end pipeline for real-time object detection and tracking using event camera data. The architecture is adapted from the BICLab SpikeYOLO ECCV 2024 implementation.","source":"@site/docs/spikeyolo-v8-tracker/introduction.md","sourceDirName":"spikeyolo-v8-tracker","slug":"/spikeyolo-v8-tracker/introduction","permalink":"/docs/spikeyolo-v8-tracker/introduction","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Type 1 Compute Documentation","permalink":"/docs/intro"},"next":{"title":"Architecture","permalink":"/docs/spikeyolo-v8-tracker/architecture"}}');var s=i(4848),r=i(8453);const o={sidebar_position:1},c="SpikeYoloV8-Tracker Introduction",a={},l=[{value:"Key Features",id:"key-features",level:2},{value:"What is Event-Based Vision?",id:"what-is-event-based-vision",level:2},{value:"Use Cases",id:"use-cases",level:2},{value:"Project Repository",id:"project-repository",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"spikeyolov8-tracker-introduction",children:"SpikeYoloV8-Tracker Introduction"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"SpikeYoloV8-Tracker"})," is a complete end-to-end pipeline for real-time object detection and tracking using event camera data. The architecture is adapted from the BICLab SpikeYOLO ECCV 2024 implementation."]}),"\n",(0,s.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"BICLab ECCV 2024 Implementation"}),": Original SpikeYOLO with I-LIF spiking neurons"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Configurable-Class Detection"}),": Detects multiple object classes dynamically"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Object Tracking"}),": Tracks objects through time using Hungarian-algorithm based ByteTracker"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Event Processing"}),": Converts event data to spike trains for SNN processing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"End-to-End Pipeline"}),": Contains highly configurable training and testing pipeline"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"what-is-event-based-vision",children:"What is Event-Based Vision?"}),"\n",(0,s.jsx)(n.p,{children:"Event cameras (also known as neuromorphic cameras) are bio-inspired sensors that capture changes in brightness at each pixel independently, rather than capturing full frames at fixed intervals. This provides:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"High Temporal Resolution"}),": Microsecond-level precision"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"High Dynamic Range"}),": >86 dB"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Low Latency"}),": Event-by-event processing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Energy Efficiency"}),": Only processes changes in the scene"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,s.jsx)(n.p,{children:"SpikeYoloV8-Tracker is ideal for:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Traffic Monitoring"}),": Real-time detection and tracking of vehicles, pedestrians, and other traffic participants"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Surveillance Systems"}),": Low-power, high-speed object tracking"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Autonomous Systems"}),": Event-based perception for robotics and autonomous vehicles"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Research"}),": Spiking neural networks for event-based vision"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"project-repository",children:"Project Repository"}),"\n",(0,s.jsxs)(n.p,{children:["The source code is available at: ",(0,s.jsx)(n.a,{href:"https://github.com/type1compute/SpikeYoloV8-Tracker",children:"https://github.com/type1compute/SpikeYoloV8-Tracker"})]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"./installation",children:"Installation Guide"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"./architecture",children:"Architecture Overview"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"./quick-start",children:"Quick Start Guide"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>c});var t=i(6540);const s={},r=t.createContext(s);function o(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);